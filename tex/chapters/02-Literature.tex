%!TEX root = ../main.tex

\chapter{Literature Review}\label{cha:literature}

As described in Chapter \ref{}, % TODO
the Prisoner's Dilemma is a very popular model in game theory and there have been many papers written about the subject.
The game has been applied to many different research areas is often used to model systems in biology \cite{Sigmund1999}, sociology \cite{Franken2005}, psychology \cite{Ishibuchi2005}, and economics \cite{Chong2005}.
The start of this chapter will give a brief overview of the literature and particularly relevant work will be highlighted.
This is followed by an outline of how Axelrod's work is currently being reproduced by an open-source community.
Finally, an introduction to fingerprinting (a technique used for identify
similar strategies) and some necessary definitions and theorems are given at the end of the chapter.


\section{Background}\label{sec:axelrodoriginal}

The political scientist Robert Axelrod held the first IPD tournament in 1980 \cite{Axelrod1980a}.
Many well-known game theorists were invited to submit strategies that would compete against each other in a round robin style format.
All strategies also competed against a random strategy (that would randomly choose between `C' and `D') and a copy of themselves.
% TODO In intro you've used $C$ and $D$, choose.
All strategies knew that the length of each game was 200 moves, and the whole tournament was repeated 5 times for reliability.
Out of the 13 strategies that were entered, TitForTat was announced as the winner and was submitted by Professor Anatol Rapoport from the Department of Psychology of the University of Toronto.
% TODO Reference Rapoport paper (there is one on TfT I believe)

TitForTat is a very simple strategy (see Section \ref{ssec:stra_titfortat}) and
as explained in \cite{Axelrod1980b}, Axelrod surmised that it won because of three defining characteristics:

\begin{itemize}
    \item `Niceness' - A strategy is said to be nice if it is not the first to defect.
    \item `Provocability' - Immediately after an opponent defects, the strategy should defect in retaliation.
    \item `Forgiveness' - The strategy is willing to continue with mutual cooperation even after some defections.
\end{itemize}

Axelrod's second tournament \cite{Axelrod1980b} saw a dramatic increase in terms of size, with 62 strategies being entered from 6 different countries.
% TODO It was actually 64 I believe (63 + 1)
The contestants ranged from a 10-year-old computer hobbyist to professors of computer science, economics, psychology, mathematics, sociology, political science and evolutionary biology.
The countries represented were the United States, Canada, Great Britain, Norway, Switzerland, and New Zealand.
Despite the fact that all contestants had full knowledge of the previous tournament, TitForTat was the overall winner once again.
One large difference in the mechanics of the first and second tournament was that the second tournament did not specify how many moves a game would last.
Instead, the game ended probabilistically with a 0.00346 chance of finishing on any given move.
This parameter was chosen so that the median length of a game would be 200 moves (in line with the first tournament).

\begin{table}[htbp]
    \centering
    \begin{tabular}{c c c c}
        \toprule
        Year & Reference & Number of Strategies & Type\\
        \midrule
        1979 & \cite{Axelrod1980a} & 13 & Standard\\
        1979 & \cite{Axelrod1980b} & 64 & Standard\\
        1984 & \cite{Axelrod1981} & 64 & Evolutionary\\
        1991 & \cite{Bendor1991} & 13 & Noisy\\
        2005 & \cite{Chong2004} & 223 & Varied\\
        2012 & \cite{Stewart2012} & 13 & Standard\\
        \bottomrule
    \end{tabular}
    \label{tab:tournament_refs}
    \caption{An overview of published tournaments}
\end{table}

Axelrod continued to extend his work by considering an evolutionary version of the tournament \cite{Axelrod1981, Axelrod1984}.
In this case, the proportion of the population playing a certain strategy depends on how the strategy performed on the previous round.
A strategy is evolutionarily stable if a population of individuals using that strategy cannot be invaded by a rare mutant adopting a different strategy \cite{Axelrod1981}.
% TODO Draw a nice picture here.

In \cite{Nowak1992, Nowak1993, Nowak1994}, Nowak extends this further by studying Spatial Games.
In his variation, the game is played on a 2 dimensional square lattice where the payoff for an individual is the sum over all interactions with its 8 nearest neighbours (see Figure \ref{fig:nowak_spatial}) and itself.
In the next generation, an individual cell is occupied with the strategy that received the highest payoff among all 8 nearest neighbours and itself.

\begin{figure}[hbtp!]
    \centering
    \begin{tikzpicture}
        \fill[gray] (1,1) rectangle (4,4);
        \fill[sol-magenta] (2,2) rectangle (3,3);
        \draw[step=1cm] (-0.9,-0.9) grid (5.9,5.9);
    \end{tikzpicture}
    \caption{The topology of Nowak's spatial variation}
    \label{fig:nowak_spatial}
\end{figure}

To simplify things, Nowak limited each cell to be either Cooperator or Defector.
Thus the game is completely deterministic and the outcome depends only on the initial configuration and the payoff matrix.
One particularly interesting result is that if a single Defector invades a world of Cooperators, long (but finite) sequences of patterns emerge.
Due to the symmetry of the game rules, all the patterns are highly symmetric and have the appearance of kaleidoscopes.

The primary purpose of \cite{Bendor1991} was to discover the effect of noise on
% TODO Introduce this paragraph better, it is not related to the previous one.
TitForTat's performance in an IPD.
As had been previously claimed its performance was significantly reduced.
The authors of \cite{Bendor1991} suggest that this is due to the provocability mentioned earlier, which in the presence of noise, can causes it to fall into unintended vendettas with other nice, but provocable strategies.
Strategies that outperformed TitForTat were far more forgiving, which enabled them to get back to mutual cooperation much faster after an accidental defection.

\section{Strategies of Particular Interest}\label{sec:individual_strategies}
Throughout this report many different strategies will be discussed and used in small examples.
This section will provide a description of some of these strategies in order to aid the reader, as a strategy's name is not always descriptive.

\subsection{TitForTat}\label{ssec:stra_titfortat}
TitForTat is the most well known strategy for playing Prisoner's Dilemma due to it winning both of Axelrod's first two tournaments.
It starts with a cooperative move and proceeds to play the same as the opponent did on the previous move \cite{Axelrod1980b, Heap2003}.
% TODO Why do you need Heap2003 here? (I don't know what that is, seems random).

\subsection{Pavlov}\label{ssec:strat_pavlov}
In \cite{Nowak1993}, the strategy Pavlov is introduced (sometimes referred to as Win-Stay Lose-Shift).
% TODO I'm almost certain this strategy occurred earlier. (See the strategy
% index on the Axelrod docs). Do the same for others.
Pavlov plays by repeating its previous move if it was successful (received payoff $T$ or $R$), and swapping the move if it was unsuccessful (received payoff $P$ or $S$).
The paper explains how this allows it to take advantage of strategies that cooperate unconditionally and can also correct occasional mistakes.

\subsection{Gradual}\label{ssec:strat_gradual}
The strategy Gradual is present in \cite{Beaufils1997}.
It begins the game by cooperating, then after the first defection of the other player, it defects one time and cooperates twice.
After the second defection of the opponent, it defects two times and cooperates twice.
After the $n^{th}$ defection it reacts with $n$ consecutive defections and then two cooperations.
In \cite{Beaufils1997} it is claimed that Gradual outperforms TitForTat and this has been confirmed by work done through the Axelrod-Python library \cite{Knight2016}.
% TODO Careful with the confirmation by the library. How is this confirmed? Is
% it just that that's what we've seen in some tournaments or is it always the
% case.

\subsection{Random}\label{ssec:strat_random}
Random plays  by choosing randomly between whether to cooperate or defect.
The probabilities of choosing cooperate or defect are not necessarily even, instead they could rely on some distribution.
% TODO The probabilities do not rely on some distribution, they are the
% distribution
We will denote the strategy that chooses to cooperate with probability $p$ as Random($p$).
For example, the strategy that randomly chooses to cooperate $20\%$ of the time and defect $80\%$ of the time would be Random($0.2$).

\subsection{Cooperator/Defector}\label{ssec:strat_coop_defect}
Cooperator and Defector are very simple.
Cooperator will choose to cooperate at every turn, and similarly Defector will choose to defect every turn.

\subsection{Cycler}\label{ssec:strat_cycler}
The strategy Cycler($s$) will repeat a given sequence of moves $s$.
For example Cycler(CD) would play CDCDCD\dots and Cycler(CDDDC) would play CDDDCCDDDCCDDDC...

\subsection{Evolved Looker-Up}\label{ssec:strat_evolved_lu}
The winning strategy in the version of Axelrod-Python used throughout this paper is Evolved Looker-Up.
% TODO Be clear what you mean by "winning": it only makes sense to describes in
% terms of the environment in which it plays right?

The author, Martin Jones, has produced a thorough explanation of how the strategy was written in \cite{MoJones}, and a brief outline will be given here.
The strategy uses a lookup table to determine the action it should take.
A lookup table is similar to a hash table when programming, where the keys could be the opponents previous moves and the values the next action the strategy should take.
% TODO A picture would be nice here.
The length of the key could be extended to include the opponents two previous moves (or more).
% TODO It is not the length of the key that is extend but the key itself
It is clear that for a key length $l$, there are $n = 2^l$ keys.
% TODO length is ambiguous, you mean "l parameters"
For each key the next action could be Cooperate or Defect, and so there are a total of $2^n$ possible lookup tables.
% TODO You've used `C`, $C$ and Cooperate. Be consistent.
If a Looker-up uses as its keys: the opponents first two moves, the opponents previous two moves, and the strategies own previous two moves.
% TODO Have a check on the version of the library used, there are a number of
% LookerUp strategies now.
Then we have $n = 2^6 = 64$ keys, and therefore $2^{64} \simeq 10^{18}$ possible lookup tables.

An evolutionary algorithm is then used to find the best possible table.
The operates by initially creating a population of many different lookup tables.
Then a new lookup table is created by combining two pre existing ones together
(similar to how DNA is joined in sexual reproduction).
% Reproduction is a general term and has nothing to do with DNA (a photo copier
% does not use DNA).
There is a probability (normally low) of some of the new lookup table mutating.
Next, several more random lookup tables are produced.
% TODO A picture would be nice here.
Finally, all lookup tables are scored and poor performers are discarded.
Then the whole process is repeated with the new generation of lookup tables.

Evolved Looker-Up was produced after 200 generations, and the final lookup table can be found in the Axelrod-Python source code.
Alternatively, the code used to produce the lookup table is given in \cite{axelrod-evolver}.
% TODO Check this against the version you're using. There's an axelrod-dojo repo
% that was used to train the latest bunch of strategies.

\section{Finite State Machines and Automatons}
An Automaton is an abstract model of a machine that can perform operations on an input.
A more general (and powerful) abstraction of an automaton is the famous Turing machine, which can perform any computational process carried out by present day computers \cite{Kandar2013}.
% TODO Find a nice (old) reference for Turing machines
In the case where an automaton has a finite set of set of states, it is referred to as a Finite State Machine.
If this FSM has outputs it is called a Moore Machine \cite{Ndjountche2016}.
A more detailed of Finite State Machines is given in Section \ref{sec:fsm}.

Finite state machines have become important in game theory for several reasons.
In the late fifties the idea of ``bounded rationality'' was explored in economics by Simon \cite{Simon1972}.
This was then extended in \cite{Rubinstein1986} where strategies that played the IPD were implemented as Moore Machines with an extra rule that added a cost associated with the complexity of the Moore Machine.
Complexity was defined to be the number of states in the machine and the author states that this was a ``fairly naive'' approach.

In \cite{Kalai1986, Kalai1988}, proofs are given that show that every strategy can be represented by an automaton.
However, in Section \ref{sec:fsm_proof} it is shown that if the length of a game in IPD is known, every strategy can be represented as a FSM.
% TODO What are these two sentences trying to say/do? It reads like the work in
% `fsm_proof` is actually a weaker version of the work done by Kalai.

% TODO Add a transition sentence, introduce what the section is.

\section{Axelrod-Python Library}
% TODO I wonder if this section should be moved to before your description of
% LookerUp strategies (or at least you should put a pointer from there to here).

The Axelrod-Python library \cite{axelrodproject} is an open source Python
package for carrying out reproducible research into the Prisoner's Dilemma.

The original aim was to recreate Axelrod's tournaments as described in Section~\ref{sec:axelrodoriginal} and verify their results.
As the library has grown, so has the overall aim.
The goal now, is "to provide a resource, with facilities for the design of new strategies and interactions between them, as well as conducting tournaments and ecological simulations for populations of strategies" \cite{Knight2016}.

As mentioned in Section~\ref{} for many of the tournaments that have been described the original source code is not available, and in the few cases where access was available there were no tests and minimal documentation.
% TODO Add pointer
The library is partly motivated by a desire to improve this situation, and there is much discussion within academia currently regarding reproducible research \cite{Crick2014, Hong2015, Procter2012, Sandve2013}.
% TODO These were the references I think I wanted you to add in the previous
% chapter. You're repeating yourself: perhaps remove one of the discussions.
Some key characteristics are that the library is:

\begin{itemize}
    \item Open: all code is released under an MIT license \cite{Rosen2004}
    \item Reproducible and well-tested: at the time of writing there is an excellent level of integrated tests with 99.73\% coverage (including property based tests: \cite{Hypothesis3.6.1})
    \item Well-documented: all features of the library are documented for ease of use and modification
    \item Extensive: 139 strategies are included, with infinitely many available in the case of parametrised strategies
    \item Extensible: easy to modify to include new strategies and to run new tournaments
\end{itemize}

Each of these items will be discussed in more detail in Section \ref{sec:dev_process}.

In listing \ref{lst:tournament} an example of how to produce a simple tournament is shown.
Lines 7 - 10 create two plots.
The first is a ranked violin plot of the mean payoff for each player and the second is a matrix plot of pair wise payoffs for each player.
These plots can be seen in figures \ref{fig:violinplot} and \ref{fig:matrixplot}.

\begin{listing}[htbp!]
    \begin{ExampleCode}
        >>> import axelrod as axl
        >>> axl.seed(0)  # Set a seed
        >>> players = [s() for s in axl.strategies]  # Create players
        >>> tournament = axl.Tournament(players)  # Create a tournament
        >>> results = tournament.play()  # Play the tournament
        >>> plot = axl.Plot(results)
        >>> p = plot.boxplot()
        >>> p.show()
        >>> q = plot.payoff()
        >>> q.show()
    \end{ExampleCode}
    \caption{Example code to produce a simple tournament}
    \label{lst:tournament}
\end{listing}
% TODO Perhaps nicer to use the strategies you've described at the beginning of
% this chapter.

\begin{figure}
%TODO
\begin{center}
\caption{Ranked violin plot of the mean payoff for each player}
\label{fig:violinplot}
\end{center}

\begin{center}
\caption{Matrix plot of pair wise payoffs for each player}
\label{fig:matrixplot}
\end{center}
\end{figure}

% TODO Add a transition sentence.

\section{Fingerprinting}\label{sec:fingerprinting}
It is easy to write a genetic algorithm to produce large numbers of strategies, however their analysis can be time consuming.
% TODO What do you mean by analysis?
% TODO What do you mean by "easy to write"? Include a reference for this claim.
Even the simple question `Are these two strategies the same?' does not always have an obvious answer.
% TODO What do you mean?
This is especially true when considering source code, as two identical strategies can be coded in different ways.
For example, differentiating between Random($0.5$) and Cycler(CD) (see Section \ref{sec:individual_strategies}) isn't trivial unless you have access to their source code.
The results of a game they play isn't necessarily enough.
% TODO Not a good example, simply seed two plays and you'll immediately see the
% difference. Go for Cycler(CD) and Alternator perhaps?

A method for comparing strategies is first given in \cite{Ashlock2004}.
Ashlock outlines several definitions, theorems and proofs concerning the construction of a fingerprint.
These are then followed by some examples, however they are of low quality and the only probe (see definition \ref{def:fingerprint}) used is TitForTat.

Ashlock then extends his fingerprinting work further in \cite{Ashlock2008}.
More examples are presented, and many different fingerprint functions are listed.
Also, a large number of the analytical fingerprint functions use a probe that is not TitForTat.
Fingerprinting is then used to to assess how three evolutionary algorithms produce different populations.
The evolutionary methods are used to train finite-state machines, lookup tables and feed forward neural nets.

% TODO This chapter/section ends rather abruptly?

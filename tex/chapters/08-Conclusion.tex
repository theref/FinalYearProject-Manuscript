%!TEX root = ../main.tex

\chapter{Conclusion}\label{cha:conclusion}

The main aim of this report was to assess the current tools for distinguishing between strategies in the Iterated Prisoner's Dilemma and implement them within the Axelrod-Python library.
The report also aimed to produce a novel approach to the problem and use this to perform some analysis on the strategies contained within Axelrod-Python.
Ultimately both of these goals were achieved and some preliminary analysis of the Axelrod-Python was completed.
In particular, an \textbf{original} result is presented in Section \ref{sec:fsm_proof} allowing the work completed in previous literature to be extended further.



\section{Overview}

As described in Chapter \ref{cha:introduction}, the Prisoner's Dilemma is a very popular model in game theory and there have been many papers written about the subject.
The game has been applied to many different research areas and is often used to model systems in biology \cite{Sigmund1999}, sociology \cite{Franken2005}, psychology \cite{Ishibuchi2005}, and economics \cite{Chong2005}.
In Chapter \ref{cha:literature} an overview of literature related to the Prisoner's Dilemma was presented, with particular emphasis on the IPD and several computer tournaments that have be held.
This was followed by a description of several common strategies that have been used throughout the report.
Also, an outline of literature relating to Finite State Machines and how they are relevant within IPD is given.
This is follow by a description of how Axelrod's work is currently being reproduced by an open-source community.
Finally, an introduction to Fingerprinting (a technique used for identifying similar strategies) is given.

In Chapter \ref{cha:theory} many definitions were presented culminating in a rigorous definition for a Fingerprint.
It was then shown that any strategy can be represented as a Finite State Machine, allowing the work of Ashlock to be extended to include any strategy to be used as a probe.
Finally, an example of how to construct an Analytical Fingerprint was provided.

In Chapter \ref{cha:implementation}, the process of implementing Fingerprint in Axelrod-Python is explained, including several algorithms equivalent to definitions from Chapter \ref{cha:theory}.
Comparisons with work produced in previous literature are made to ensure that results produced are correct.

In Chapter \ref{cha:results} several fingerprints were examined in detail.
This included discussions of individual fingerprints, a comparison of fingerprints for a strategy with a varying parameter, and also the importance of probe selection.

In Chapter \ref{cha:machinelearning} a new approach to identifying similar strategies using Machine Learning was given.
The process of training and assessing the model was described in detail, followed by some preliminary results of the models performance.
Finally, in Chapter \ref{cha:applying-model}, the model was used to identify equivalent strategies.
First, a level of the model's sensitivity was obtained using a variety of memory one strategies from Axelrod-Python.
This was followed by the model being applied to all strategies within Axelrod-Python; producing network graphs of strategies the model considered identical.

The networks graphs highlighted several cases where the equivalence of strategies was already know, for example Alternator and Cycler(DC).
However there were several neighbourhoods which contained unrelated strategies and there is further work required to understand whether they are actually identical or not.



\section{The Future}

Due to time constraints, there were many interesting topics that could not be investigated fully.
Future work could include examining more Fingerprint plots to better understand how the behaviour of a strategy affects the plot, in a similar way to Chapter \ref{cha:results}.
In addition, using more probes to produce Fingerprints to study the effect they have.

In Chapters \ref{cha:machinelearning} and \ref{cha:applying-model}, only one probe is used to produce the data the model is trained on.
The probe was selected to be in line with previous literature and it is unlikely that it is the best choice.
The possibility of using multiple probes to train the model was also not considered.
In future work, a probe strategy which best identifies similar strategies could be found.
Due to the work outlined in Chapter \ref{cha:theory}, this could be a highly trained strategy with no FSM representation.

Finally, in Chapter \ref{cha:applying-model}, many of the neighbourhood network graphs were not discussed.
A more detailed inspection of the source code for the strategies in the same network could yield interesting results regarding identical strategies within Axelrod-Python.

The \textbf{original} result described in Chapter \ref{cha:theory} combined with the novel approach outlined in Chapter \ref{cha:machinelearning} have produced a large amount of potential new research.
With regards to Axelrod-Python, more analysis of the strategies it contains could be carried out.
However, more generally, the method of using Machine Learning should be refined by finding the best probe strategy and also the best strategies to base the model on.
